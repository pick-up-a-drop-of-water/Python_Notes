#### 迅速读取大型csv数据文件
> - 🔗[参考链接](https://www.kaggle.com/szelee/how-to-import-a-csv-file-of-55-million-rows)
```python
start_time = datetime.now()
print("开始时间: ", start_time.strftime("%Y-%m-%d %H:%M:%S"))


def display_runtime():
    end_time = datetime.now()
    print("结束时间: ", end_time.strftime("%Y-%m-%d %H:%M:%S"))
    run_time = end_time - start_time
    print("运行时间: ", run_time.seconds, "秒")


def rapid_read_csv():
    with open("datasets/encoded_input_data.csv") as f:
        n_rows = len(f.readlines())
        df_temp = dd.read_csv("datasets/encoded_input_data.csv", header=None)
    print("CSV数据行数: ", n_rows)
    print(df_temp.head())
    print(df_temp.describe().compute())     # dask is lazy. It only works when it is asked explicitly with compute()
    display_runtime()


rapid_read_csv()
```
